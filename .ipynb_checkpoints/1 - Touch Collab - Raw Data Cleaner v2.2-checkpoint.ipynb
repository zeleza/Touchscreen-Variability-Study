{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to take raw touchscreen data and clean it\n",
    "Written by Ariel Zeleznikow-Johnston\n",
    "\n",
    "arielz@student.unimelb.edu.au\n",
    "\n",
    "August 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all the relevant *.csv files, make a list of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QBI raw.csv']\n"
     ]
    }
   ],
   "source": [
    "cur_dir = os.getcwd()\n",
    "full_file_list = os.listdir(cur_dir)\n",
    "csv_file_list = glob.glob('*.csv')\n",
    "# get rid of already compiled files\n",
    "[x for x in csv_file_list if \"collated\" not in x]\n",
    "\n",
    "df = pd.DataFrame\n",
    "print(csv_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check haven't forgotten to make unique animal IDs\n",
    "def missing_ID_check(df):\n",
    "    if 'Unique_Animal_ID' in df.columns:\n",
    "        missing_IDs = df[df['Unique_Animal_ID'].isna()==True]\n",
    "        if (missing_IDs.empty != True):\n",
    "            print(\"Missing some Unique_Animal_ID entries in: \")\n",
    "            print(missing_IDs)\n",
    "            return True\n",
    "        return False\n",
    "    else:\n",
    "        print(\"Missing all Unique_Animal_ID values in: \")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# give animals unique IDs\n",
    "def unique_ID_gen(df):\n",
    "    df['Unique_Animal_ID'] = df['Animal_Id'].map(str) + df['Cohort'].map(str)\n",
    "    df['Unique_Cohort'] = df['Cohort'].map(str) + df['User'].map(str) + df['Lab site'].map(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge all the files\n",
    "df = pd.concat([pd.read_csv(file) for file in csv_file_list], ignore_index = True, sort=True)\n",
    "if 'Unique_Animal_ID' in df.columns:\n",
    "    df = df.drop(columns=['Unique_Animal_ID'])\n",
    "# generate new unique IDs\n",
    "df = unique_ID_gen(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial cleaning to remove duplicates, false starts/escapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check for duplicate row entries, keep a list, delete from main dataset\n",
    "def duplicate_checker(df):\n",
    "    try:\n",
    "        duplicates = df[df.duplicated(subset=['Animal_Id','Date','Session_Id','TimeStamp'])==True]\n",
    "        if duplicates.empty != True: #let us know if there are errors\n",
    "            print('WARNING: duplicate entries!')\n",
    "        print(\"Checked for duplicates\")\n",
    "        return df.drop_duplicates()\n",
    "    except:\n",
    "        print(\"error with duplicate checking\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# animal & day sorter\n",
    "def animal_day_sorter(df):\n",
    "    try:\n",
    "        df.sort_values(by=['Unique_Animal_ID','Day'])\n",
    "        return df\n",
    "    except:\n",
    "        print(\"error with day/animal sorting\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check for false starts (time of last trial under 5 minutes) & also sequential day adder\n",
    "def false_start_checker(df):\n",
    "    removed_trials = 0\n",
    "    try:\n",
    "        time_threshold = 300 # cutoff set at 5 minutes\n",
    "        cleaned_df = df.iloc[0:0] # make new dataframe with old headers\n",
    "\n",
    "        animal_list = df['Unique_Animal_ID'].unique() \n",
    "        for animal in animal_list:\n",
    "            print(\"False start checking: \",animal)\n",
    "            temp_df = df[df['Unique_Animal_ID']==animal]\n",
    "            \n",
    "            # also redate while this is running anyway\n",
    "            days = temp_df['Day'].unique()\n",
    "            day_list = days.tolist()\n",
    "            day_list = sorted(day_list)\n",
    "            count = 1\n",
    "            \n",
    "            print(\"Examining day: \", end = \"\")\n",
    "            for day in days:\n",
    "                print(\" \" + str(day) + \" \", end = \"\")\n",
    "                # redate\n",
    "                temp_df2 = temp_df[temp_df['Day']==day]\n",
    "                temp_df2['Sequential Day'] = count\n",
    "                count += 1\n",
    "                # remove if too short\n",
    "                if temp_df2['TimeStamp'].max() > time_threshold:\n",
    "                    cleaned_df = cleaned_df.append(temp_df2)              \n",
    "                else:\n",
    "                    print('WARNING: suspiciously short sessions. Data excluded')\n",
    "                    removed_trials += len(temp_df2)\n",
    "            print(\"\")\n",
    "        print(\"Checked for false starts\")\n",
    "        return cleaned_df\n",
    "    except:\n",
    "        print(\"error with false start removal\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked for duplicates\n",
      "False start checking:  Z02CCohort 1\n",
      "Examining day:  0  1  2  3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4  5  6  7  8  9  10 \n",
      "False start checking:  Z01BCohort 1\n",
      "Examining day:  0  1  2  3 \n",
      "False start checking:  Z04CCohort 1\n",
      "Examining day:  0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21 \n",
      "False start checking:  Z03CCohort 1\n",
      "Examining day:  0  1  2  3  4  5 \n",
      "False start checking:  Z02ACohort 1\n",
      "Examining day:  0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22 \n",
      "False start checking:  A06DCohort 1\n",
      "Examining day:  0 \n",
      "False start checking:  Z05DCohort 1\n",
      "Examining day:  0  1  2  3  4  5 \n",
      "False start checking:  A03CCohort 1\n",
      "Examining day:  0 \n",
      "False start checking:  Z06CCohort 1\n",
      "Examining day:  0  1  2  3  4  5  6  7  8  9  10  11  12  13  14 \n",
      "False start checking:  Z04ACohort 1\n",
      "Examining day:  0  1  2  3  4  5  6  7  8  9  10  11 \n",
      "False start checking:  Z01CCohort 1\n",
      "Examining day:  0  1  2  3  4  5  6 \n",
      "False start checking:  Z03DCohort 1\n",
      "Examining day:  0  1  2  3  4  5  6  7  8 \n",
      "False start checking:  Z02DCohort 1\n",
      "Examining day:  0  1  2  3  4  5  6  7  8  9  10  11 \n",
      "False start checking:  Z06ACohort 1\n",
      "Examining day:  0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15 \n",
      "False start checking:  A03DCohort 1\n",
      "Examining day:  0 \n",
      "False start checking:  Z04DCohort 1\n",
      "Examining day:  0  1  2  3  4  5  6  7  8 \n",
      "False start checking:  Z01DCohort 1\n",
      "Examining day:  0  1  2  3  4  5 \n",
      "False start checking:  Z05ACohort 1\n",
      "Examining day:  0  1  2  3  4  5  6 \n",
      "False start checking:  Z02BCohort 1\n",
      "Examining day:  0  1  2  3  4  5 \n",
      "False start checking:  Z06DCohort 1\n",
      "Examining day:  0  1  2  3  4  5  6  7  8  9 \n",
      "False start checking:  Z04BCohort 1\n",
      "Examining day:  0  1  2  3  4  5  6  7  8  9  10  11  13 \n",
      "False start checking:  Z03ACohort 1\n",
      "Examining day:  0  1  2  3  4  5  6 \n",
      "False start checking:  Z05BCohort 1\n",
      "Examining day:  0  1  2  3  4  5  6  7  8 \n",
      "False start checking:  Z06BCohort 1\n",
      "Examining day:  0  1  2  3  4  5  6  7 \n",
      "False start checking:  Z01ACohort 1\n",
      "Examining day:  0  1  2  3  4  5  6 \n",
      "False start checking:  Z03BCohort 1\n",
      "Examining day:  0  1  2  3  4  5 \n",
      "False start checking:  Z05CCohort 1\n",
      "Examining day:  0  1  2  3  4  5  6  7 \n",
      "Checked for false starts\n"
     ]
    }
   ],
   "source": [
    "# Run the cleaning\n",
    "df = duplicate_checker(df)\n",
    "df = animal_day_sorter(df)\n",
    "df = false_start_checker(df)\n",
    "df = animal_day_sorter(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pc_score(df,day):\n",
    "    try:\n",
    "        main_trials = df[df['Correction_Trial']==0] # don't look at correction trials\n",
    "        score_sum = float(main_trials['Correct_Response'].sum())\n",
    "        trial_num = float(len(main_trials))\n",
    "        score = score_sum/trial_num\n",
    "        return score\n",
    "    except:\n",
    "        print(\"PROBLEM: Problem with scoring! Set score for this session: \",day,\" : to zero\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove everything that's not in VD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# also need to add a feature so that if the schedule name changes then it's no longer VD\n",
    "\n",
    "def vd_obtainer(df):\n",
    "    try:\n",
    "        vd_criterion_pc = 0.8 # criterion set at 80%\n",
    "        vd_criterion_sessions = 2 # number of sessions animals need to reach criterion performance for\n",
    "        cleaned_df = df.iloc[0:0] # make new dataframe with old headers\n",
    "        animal_list = df['Unique_Animal_ID'].unique() # get unique animal list\n",
    "        for animal in animal_list:\n",
    "            temp_df3 = df.iloc[0:0] # make new dataframe with old headers, in case animal never hits criterion\n",
    "            animal_count = 0\n",
    "            temp_df1 = df[df['Unique_Animal_ID']==animal]\n",
    "            days = temp_df1['Day'].unique()\n",
    "            # make sure the schedule doesn't change\n",
    "            original_schedule = temp_df1[0:1]['Schedule'].item()\n",
    "            for day in days:\n",
    "                temp_df2 = temp_df1[temp_df1['Day']==day]\n",
    "                #check to see if it met criterion\n",
    "                score = pc_score(temp_df2,day)\n",
    "                day_schedule = temp_df2[0:1]['Schedule'].item()\n",
    "                if ((score < vd_criterion_pc) and (day_schedule==original_schedule)):\n",
    "                    temp_df3 = temp_df3.append(temp_df2)\n",
    "                    animal_count = 0 # reset day counter to zero if animal dropped below criterion performance\n",
    "                elif(day_schedule==original_schedule):\n",
    "                    temp_df3 = temp_df3.append(temp_df2)\n",
    "                    animal_count += 1\n",
    "                    if (animal_count == vd_criterion_sessions):\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "            if(animal_count==2):\n",
    "                cleaned_df = cleaned_df.append(temp_df3)\n",
    "                print(\"VD data obtained for animal: \",animal)\n",
    "            else:\n",
    "                # animal never reached criterion\n",
    "                print(\"Animal: \",animal,\" never reached criterion!\")\n",
    "        print(\"VD Data obtained successfully!\")\n",
    "        return(cleaned_df)\n",
    "    except:\n",
    "        print(\"WARNING: problem obtaining VD data!\")        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VD data obtained for animal:  Z02CCohort 1\n",
      "VD data obtained for animal:  Z01BCohort 1\n",
      "VD data obtained for animal:  Z04CCohort 1\n",
      "VD data obtained for animal:  Z03CCohort 1\n",
      "VD data obtained for animal:  Z02ACohort 1\n",
      "Animal:  A06DCohort 1  never reached criterion!\n",
      "VD data obtained for animal:  Z05DCohort 1\n",
      "Animal:  A03CCohort 1  never reached criterion!\n",
      "Animal:  Z06CCohort 1  never reached criterion!\n",
      "VD data obtained for animal:  Z04ACohort 1\n",
      "VD data obtained for animal:  Z01CCohort 1\n",
      "VD data obtained for animal:  Z03DCohort 1\n",
      "VD data obtained for animal:  Z02DCohort 1\n",
      "VD data obtained for animal:  Z06ACohort 1\n",
      "Animal:  A03DCohort 1  never reached criterion!\n",
      "VD data obtained for animal:  Z04DCohort 1\n",
      "VD data obtained for animal:  Z01DCohort 1\n",
      "VD data obtained for animal:  Z05ACohort 1\n",
      "VD data obtained for animal:  Z02BCohort 1\n",
      "VD data obtained for animal:  Z06DCohort 1\n",
      "VD data obtained for animal:  Z04BCohort 1\n",
      "VD data obtained for animal:  Z03ACohort 1\n",
      "VD data obtained for animal:  Z05BCohort 1\n",
      "VD data obtained for animal:  Z06BCohort 1\n",
      "VD data obtained for animal:  Z01ACohort 1\n",
      "VD data obtained for animal:  Z03BCohort 1\n",
      "VD data obtained for animal:  Z05CCohort 1\n",
      "VD Data obtained successfully!\n"
     ]
    }
   ],
   "source": [
    "vd_df = vd_obtainer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add light-cycle adjusted time of day\n",
    "def adjust_tod(df):\n",
    "    df['Adj_TOD'] = (pd.to_datetime(df['Time'], format = \"%H:%M\") \n",
    "                     - pd.to_datetime(df['Lights off'], format = \"%H:%M\")).dt.total_seconds()/60\n",
    "adjust_tod(vd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make Stimulus labels\n",
    "\n",
    "def stimulus_label(row):\n",
    "    if row['Schedule'] == '270 - Ariel - Mouse Pairwise Discrimination v3':\n",
    "        return '225 contrast'\n",
    "    if row['Schedule'] == 'Mouse Pairwise Discrimination right':\n",
    "        return '225 contrast'\n",
    "    if row['Schedule'] == 'Mouse Pairwise Discrimination left':\n",
    "        return '45 contrast'\n",
    "    if row['Schedule'] == '45 - Ariel - Mouse Pairwise Discrimination v3':\n",
    "        return '45 contrast'\n",
    "    if row['Schedule'] == 'Ariel - Mouse Pairwise Discrimination v3 - 1 (flash)':\n",
    "        return 'flash'\n",
    "    if row['Schedule'] == 'Ariel - Mouse Pairwise Discrimination v3 - 2 (wheel)':\n",
    "        return 'wheel'\n",
    "    if row['Schedule'] == 'Mouse Pairwise Discrimination v3 dots':\n",
    "        return 'dots'\n",
    "    if row['Schedule'] == 'Mouse Pairwise Discrimination v3 fan':\n",
    "        return 'fan'\n",
    "\n",
    "vd_df['Stimulus'] = vd_df.apply(stimulus_label, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vd_df.to_csv(\"vd_collated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get rid of non-WT animals\n",
    "#vd_df_WT = vd_df[vd_df['Genotype']=='WT']\n",
    "# get rid of non-SH animals\n",
    "#vd_df_WT.drop(vd_df_WT.loc[vd_df_WT['Housing']=='EE'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vd_df_WT.to_csv(\"vd_collated - just SH WTs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"vd_and_rl_collated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
